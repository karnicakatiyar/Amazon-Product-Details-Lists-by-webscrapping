{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "7695243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Get product title\n",
    "def get_name(soup):\n",
    "    \n",
    "    try:\n",
    "        name_string = soup.find(\"span\", attrs={\"id\":'productTitle'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        name_string = \"\"    \n",
    "\n",
    "    return name_string\n",
    "\n",
    "# Get product price\n",
    "def get_price(soup):\n",
    "\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'class':'a-price-whole'}).text\n",
    "        try:\n",
    "            price = float(price.replace(',',''))\n",
    "        except:\n",
    "            price = float(eval(price))\n",
    "\n",
    "    except AttributeError:\n",
    "        price = \"\"    \n",
    "\n",
    "    return price\n",
    "\n",
    "# Get product ratings\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = float(soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip().split(\"out\")[0])\n",
    "        \n",
    "    except AttributeError:\n",
    "        \n",
    "        try:\n",
    "            rating = float(soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip().split(\"out\")[0])\n",
    "        except:\n",
    "            rating = \"\"    \n",
    "\n",
    "    return rating\n",
    "\n",
    "# Get number of user reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = int(soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip().split(' ')[0].replace(',',''))\n",
    "        \n",
    "    except AttributeError:\n",
    "        review_count = \"\"    \n",
    "\n",
    "    return review_count\n",
    "\n",
    "\n",
    "# Get description\n",
    "def get_description(soup):\n",
    "    try:\n",
    "        description = soup.find(\"ul\", attrs={\"class\":'a-unordered-list a-vertical a-spacing-mini'}).text\n",
    "    except:\n",
    "        description = ''\n",
    "        \n",
    "    return description\n",
    "\n",
    "# Get product description\n",
    "def get_prod_description(soup):\n",
    "    try:\n",
    "        prod_description = soup.find(\"div\", attrs={\"id\":'productDescription'}).text.replace('\\n','')\n",
    "    except:\n",
    "        prod_description = ''\n",
    "        \n",
    "    return prod_description\n",
    "\n",
    "# Get ASIN\n",
    "def get_asin(soup):\n",
    "    try:\n",
    "        asin = str(soup.find(\"input\",attrs={\"id\":\"ASIN\"})).split(\"value=\")[-1][1:-3]\n",
    "    except:\n",
    "        try:\n",
    "            table = soup.find(\"table\", attrs={\"id\":\"productDetails_detailBullets_sections1\"})\n",
    "            rows = table.find_all('tr')\n",
    "            values ={\"title\":[],\"value\":[]}\n",
    "            for row in rows:\n",
    "                head = row.find('th').text.strip()\n",
    "                cols = row.find('td').text.strip()\n",
    "                values[\"value\"].append(cols)\n",
    "                values[\"title\"].append(head)\n",
    "\n",
    "            asin_df = pd.DataFrame(values)\n",
    "            manufacturer = asin_df[asin_df[\"title\"]==\"ASIN\"][\"value\"].iloc[0]\n",
    "        except:\n",
    "            try:\n",
    "                asin_temp = soup.find(\"div\", attrs={\"id\":\"detailBullets_feature_div\"})\n",
    "                asin_temp = asin_temp.find(\"ul\",attrs={\"class\":\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\"}).find_all(\"li\")\n",
    "                for each in asin_temp:\n",
    "                    values = each.text.split(\":\")\n",
    "                    values = [temp.replace(\"\\u200f\",'').replace(\"\\u200e\",'').strip() for temp in values]\n",
    "                    if(values[0]==\"ASIN\"):\n",
    "                        return (values[-1])\n",
    "            except:\n",
    "                asin = ''\n",
    "        \n",
    "    return asin\n",
    "        \n",
    "# Get manufacturer name\n",
    "def get_manufacturer(soup):\n",
    "    try:\n",
    "        table = soup.find(\"table\", attrs={\"id\":\"productDetails_detailBullets_sections1\"})\n",
    "        rows = table.find_all('tr')\n",
    "        values ={\"title\":[],\"value\":[]}\n",
    "        for row in rows:\n",
    "            head = row.find('th').text.strip()\n",
    "            cols = row.find('td').text.strip()\n",
    "            values[\"value\"].append(cols)\n",
    "            values[\"title\"].append(head)\n",
    "        \n",
    "        manu_df = pd.DataFrame(values)\n",
    "        manufacturer = manu_df[manu_df[\"title\"]==\"Manufacturer\"][\"value\"].iloc[0]\n",
    "    except:\n",
    "        try:\n",
    "            manufacturer = soup.find(\"div\", attrs={\"id\":\"detailBullets_feature_div\"})\n",
    "            manufacturer = manufacturer.find(\"ul\",attrs={\"class\":\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\"}).find_all(\"li\")\n",
    "            for each in manufacturer:\n",
    "                values = each.text.split(\":\")\n",
    "                values = [temp.replace(\"\\u200f\",'').replace(\"\\u200e\",'').strip() for temp in values]\n",
    "                if(values[0]==\"Manufacturer\"):\n",
    "                    return (values[-1])\n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            manufacturer = ''\n",
    "    \n",
    "    return manufacturer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f93c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching products from page 1\n"
     ]
    }
   ],
   "source": [
    "HEADERS = ({'User-Agent':\n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "                'Accept-Language': 'en-US, en;q=0.5'})\n",
    "URL = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1\"\n",
    "\n",
    "data = {\"product_url\":[], \"product_name\":[], \"product_price\":[],\"rating\":[],\"number_reviews\":[],\n",
    "        \"description\":[],\"product_ASIN\":[], \"product_description\":[], \"manufacturer\":[]}\n",
    "\n",
    "# Traverse through each page link\n",
    "for i in range(1,21):\n",
    "    print(\"Fetching products from page {}\".format(i))\n",
    "    \n",
    "    # Create url of each search result page ( appending last character with page number )\n",
    "    url = URL[:-1] + str(i)\n",
    "    \n",
    "    # Traversing inside each url\n",
    "    webpage = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")    # Create soup\n",
    "    \n",
    "    # Find all product list\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "    links = [(\"https://www.amazon.in\"+link.get('href')) for link in links]  # store links\n",
    "    \n",
    "    # Traverse through each product link.\n",
    "    for link in links:\n",
    "        webpage = requests.get(link, headers=HEADERS)\n",
    "        soup = BeautifulSoup(webpage.content, \"lxml\")    # Create soup\n",
    "        \n",
    "        # Part 1 of assignment\n",
    "        data[\"product_url\"].append(link)\n",
    "        data[\"product_name\"].append(get_name(soup))\n",
    "        data[\"product_price\"].append(get_price(soup))\n",
    "        data[\"rating\"].append(get_rating(soup))\n",
    "        data[\"number_reviews\"].append(get_review_count(soup))\n",
    "        \n",
    "        # Part 2 of assignment\n",
    "        data[\"description\"].append(get_description(soup))\n",
    "        data[\"product_ASIN\"].append(get_asin(soup))\n",
    "        data[\"product_description\"].append(get_prod_description(soup))\n",
    "        data[\"manufacturer\"].append(get_manufacturer(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to dataframe\n",
    "final = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b108f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376a24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
